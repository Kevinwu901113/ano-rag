# === 输入配置 ===
input:
  path: "data/test.jsonl"  # 可改为 data/your_folder

# === v2 必需 ===
retrieval_v2:
  gate:
    # 候选门控（结构先验 + 轻量相似）
    jacc_char_min: 0.18      # 字符 Jaccard 最小阈值（第一次跑可放松到 0.15，再慢慢收紧）
    anchors_min_shared: 1    # 锚点最少共享数
    topB: 20                 # 每个中心 note 的候选上限
    use_struct_prior: true   # 启用弱图结构先验
  dbtes:
    m: 6           # 每组最多候选数（组内锦标赛）
    rounds: 2      # 双轮
    keep_k: 3      # 最终保留边数（与下方 mmr.keep_k 对齐）
    # 可选：每轮 LLM prompt 最大字符/词数上限（如你在 router 里计费）
    # max_tokens_per_call: 800
  # 多样性去冗：如果没有向量，会用标题字符 Jaccard 兜底
mmr:
  keep_k: 3

retriever:
  hybrid:
    enabled: true
    fusion_topk: 50
    bm25_topk: 50
    vector_topk: 50
    bm25_k1: 1.5
    bm25_b: 0.75
    fusion:
      strategy: zscore
      weights:
        bm25: 1.0
        vector: 1.0
      rrf_k: 60

embedding:
  model: "BAAI/bge-m3"
  dimension: 1024
  normalize: true
  batch_size: 32
  # instruction: ""        # 可选，统一前缀
  # note_instruction: ""   # 可选，笔记编码前缀
  # query_instruction: ""  # 可选，问题编码前缀

ann:
  enabled: false
  index_path: "vector_index"
  metric: ip
  topk_raw: 50
  params:
    M: 32
    ef_construction: 200
    ef_search: 64

graph_v2:
  degree_cap: 20   # 每节点最大出边，避免星型爆炸

# main.py 检索阶段（question→段落）上下文拼接数量
retrieval_topk: 5

metrics:
  enable: false
  topk_eval: 50
  baseline:
    path: null
    metrics: {}
    enforce_non_negative: false

logging:
  level: INFO
  json: true

# === LLM 路由（LM Studio + Ollama）===
llm_pool:
  backends:
    - name: lmstudio
      weight: 3
      max_inflight: 4
      timeout_s: 30
    - name: ollama
      weight: 1
      max_inflight: 2
      timeout_s: 30
  breaker:
    fail_threshold: 3
    cool_down_s: 60
