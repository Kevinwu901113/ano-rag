#!/usr/bin/env python3
"""
ç®€åŒ–çš„ vLLM Provider æµ‹è¯•è„šæœ¬
é¿å…å¤æ‚çš„ä¾èµ–é—®é¢˜ï¼Œåªæµ‹è¯•æ ¸å¿ƒåŠŸèƒ½
"""

import sys
import os
import asyncio
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# ç›´æ¥å¯¼å…¥ vLLM provider
from llm.providers.vllm_openai import VLLMOpenAIProvider

def test_vllm_provider():
    """æµ‹è¯• vLLM Provider åŸºæœ¬åŠŸèƒ½"""
    print("=== vLLM Provider æµ‹è¯• ===")
    
    # æµ‹è¯•é…ç½®
    config = {
        'base_url': 'http://127.0.0.1:8001/v1',
        'model': 'qwen2_5_0_5b',
        'api_key': 'EMPTY',
        'temperature': 0.0,
        'max_tokens': 256
    }
    
    try:
        # åˆ›å»º provider å®ä¾‹
        provider = VLLMOpenAIProvider(**config)
        print(f"âœ“ Provider åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•è¿æ¥
        if provider.is_available():
            print("âœ“ vLLM æœåŠ¡è¿æ¥æˆåŠŸ")
            
            # æµ‹è¯•æ¨¡å‹åˆ—è¡¨
            models = provider.list_models()
            print(f"âœ“ å¯ç”¨æ¨¡å‹: {models}")
            
            # æµ‹è¯•èŠå¤©åŠŸèƒ½
            messages = [
                {"role": "user", "content": "ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚"}
            ]
            
            response = provider.chat(messages)
            print(f"âœ“ èŠå¤©æµ‹è¯•æˆåŠŸ: {response[:100]}...")
            
            # æµ‹è¯•æµå¼è¾“å‡º
            print("\n=== æµå¼è¾“å‡ºæµ‹è¯• ===")
            for chunk in provider.stream(messages):
                print(chunk, end='', flush=True)
            print("\nâœ“ æµå¼è¾“å‡ºæµ‹è¯•å®Œæˆ")
            
        else:
            print("âœ— vLLM æœåŠ¡ä¸å¯ç”¨")
            print("è¯·ç¡®ä¿ vLLM æœåŠ¡å·²å¯åŠ¨:")
            print("python -m vllm.entrypoints.openai.api_server \\")
            print("  --model Qwen/Qwen2.5-0.5B-Instruct \\")
            print("  --served-model-name qwen2_5_0_5b \\")
            print("  --dtype float16 \\")
            print("  --max-model-len 4096 \\")
            print("  --gpu-memory-utilization 0.80 \\")
            print("  --port 8001")
            return False
            
    except Exception as e:
        print(f"âœ— æµ‹è¯•å¤±è´¥: {e}")
        return False
    
    return True

async def test_async_functionality():
    """æµ‹è¯•å¼‚æ­¥åŠŸèƒ½"""
    print("\n=== å¼‚æ­¥åŠŸèƒ½æµ‹è¯• ===")
    
    config = {
        'base_url': 'http://127.0.0.1:8001/v1',
        'model': 'qwen2_5_0_5b',
        'api_key': 'EMPTY',
        'temperature': 0.0,
        'max_tokens': 128
    }
    
    try:
        provider = VLLMOpenAIProvider(**config)
        
        if not provider.is_available():
            print("âœ— vLLM æœåŠ¡ä¸å¯ç”¨ï¼Œè·³è¿‡å¼‚æ­¥æµ‹è¯•")
            return False
        
        messages = [
            {"role": "user", "content": "è¯·ç”¨ä¸€å¥è¯ä»‹ç»äººå·¥æ™ºèƒ½ã€‚"}
        ]
        
        # æµ‹è¯•å¼‚æ­¥èŠå¤©
        response = await provider.async_chat(messages)
        print(f"âœ“ å¼‚æ­¥èŠå¤©æµ‹è¯•æˆåŠŸ: {response}")
        
        # æµ‹è¯•å¼‚æ­¥æµå¼è¾“å‡º
        print("\n=== å¼‚æ­¥æµå¼è¾“å‡ºæµ‹è¯• ===")
        async for chunk in provider.async_stream(messages):
            print(chunk, end='', flush=True)
        print("\nâœ“ å¼‚æ­¥æµå¼è¾“å‡ºæµ‹è¯•å®Œæˆ")
        
        return True
        
    except Exception as e:
        print(f"âœ— å¼‚æ­¥æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("å¼€å§‹ vLLM Provider æµ‹è¯•...\n")
    
    # åŒæ­¥æµ‹è¯•
    sync_success = test_vllm_provider()
    
    # å¼‚æ­¥æµ‹è¯•
    async_success = asyncio.run(test_async_functionality())
    
    print("\n=== æµ‹è¯•æ€»ç»“ ===")
    print(f"åŒæ­¥åŠŸèƒ½: {'âœ“ é€šè¿‡' if sync_success else 'âœ— å¤±è´¥'}")
    print(f"å¼‚æ­¥åŠŸèƒ½: {'âœ“ é€šè¿‡' if async_success else 'âœ— å¤±è´¥'}")
    
    if sync_success and async_success:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼vLLM Provider å·¥ä½œæ­£å¸¸ã€‚")
        return 0
    else:
        print("\nâŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ vLLM æœåŠ¡çŠ¶æ€ã€‚")
        return 1

if __name__ == "__main__":
    exit(main())