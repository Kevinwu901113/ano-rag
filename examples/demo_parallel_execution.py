#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤šæ¨¡å‹å¹¶è¡Œæ‰§è¡Œæ¼”ç¤º
å±•ç¤ºå¦‚ä½•ä½¿ç”¨ä¼˜åŒ–çš„å¹¶è¡Œæ‰§è¡ŒåŠŸèƒ½æé«˜æ•´ä½“æ‰§è¡Œæ•ˆç‡
"""

import time
from typing import List
from loguru import logger
from optimized_multi_model_client import OptimizedMultiModelClient
from llm.multi_model_client import MultiModelClient

def demo_performance_comparison():
    """æ¼”ç¤ºæ€§èƒ½å¯¹æ¯”ï¼šä¸²è¡Œ vs å¹¶å‘ vs çœŸæ­£å¹¶è¡Œ"""
    logger.info("ğŸ¯ å¤šæ¨¡å‹å¹¶è¡Œæ‰§è¡Œæ€§èƒ½å¯¹æ¯”æ¼”ç¤º")
    logger.info("="*60)
    
    # å‡†å¤‡æµ‹è¯•æ•°æ®
    test_prompts = [
        "è¯·ç”¨ä¸€å¥è¯æè¿°äººå·¥æ™ºèƒ½çš„å‘å±•å‰æ™¯ã€‚",
        "è§£é‡Šä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ï¼Œç”¨ç®€å•çš„è¯­è¨€ã€‚",
        "æ¨èä¸€ä¸ªå­¦ä¹ ç¼–ç¨‹çš„æœ‰æ•ˆæ–¹æ³•ã€‚",
        "æè¿°äº‘è®¡ç®—å¯¹ä¼ä¸šçš„ä¸»è¦ä¼˜åŠ¿ã€‚",
        "ä»€ä¹ˆæ˜¯åŒºå—é“¾æŠ€æœ¯çš„æ ¸å¿ƒç‰¹ç‚¹ï¼Ÿ",
        "ä»‹ç»æœºå™¨å­¦ä¹ åœ¨åŒ»ç–—é¢†åŸŸçš„åº”ç”¨ã€‚"
    ]
    
    try:
        # åˆ›å»ºå®¢æˆ·ç«¯
        standard_client = MultiModelClient()
        optimized_client = OptimizedMultiModelClient()
        
        logger.info(f"ğŸ“Š æµ‹è¯•æ•°æ®: {len(test_prompts)} ä¸ªæç¤º")
        logger.info(f"ğŸ–¥ï¸ å¯ç”¨å®ä¾‹: {len(standard_client.model_instances)} ä¸ª")
        
        # æ–¹æ³•1: ä¸²è¡Œæ‰§è¡Œ
        logger.info("\nğŸŒ æ–¹æ³•1: ä¸²è¡Œæ‰§è¡Œ")
        start_time = time.time()
        serial_results = []
        for i, prompt in enumerate(test_prompts):
            logger.info(f"   å¤„ç†è¯·æ±‚ {i+1}/{len(test_prompts)}...")
            result = standard_client.generate(prompt, max_tokens=50)
            serial_results.append(result)
        serial_time = time.time() - start_time
        logger.info(f"   â±ï¸ ä¸²è¡Œæ‰§è¡Œè€—æ—¶: {serial_time:.2f}s")
        
        # æ–¹æ³•2: æ ‡å‡†å¹¶å‘æ‰§è¡Œ
        logger.info("\nğŸ”„ æ–¹æ³•2: æ ‡å‡†å¹¶å‘æ‰§è¡Œ (generate_concurrent)")
        start_time = time.time()
        concurrent_results = standard_client.generate_concurrent(test_prompts, max_tokens=50)
        concurrent_time = time.time() - start_time
        logger.info(f"   â±ï¸ å¹¶å‘æ‰§è¡Œè€—æ—¶: {concurrent_time:.2f}s")
        
        # æ–¹æ³•3: ä¼˜åŒ–å¹¶è¡Œæ‰§è¡Œ
        logger.info("\nğŸš€ æ–¹æ³•3: ä¼˜åŒ–å¹¶è¡Œæ‰§è¡Œ (generate_parallel)")
        start_time = time.time()
        parallel_results = optimized_client.generate_parallel(test_prompts, max_tokens=50)
        parallel_time = time.time() - start_time
        logger.info(f"   â±ï¸ å¹¶è¡Œæ‰§è¡Œè€—æ—¶: {parallel_time:.2f}s")
        
        # æ€§èƒ½åˆ†æ
        logger.info("\nğŸ“ˆ æ€§èƒ½åˆ†æ:")
        logger.info("="*40)
        
        concurrent_speedup = serial_time / concurrent_time if concurrent_time > 0 else 1.0
        parallel_speedup = serial_time / parallel_time if parallel_time > 0 else 1.0
        parallel_vs_concurrent = concurrent_time / parallel_time if parallel_time > 0 else 1.0
        
        logger.info(f"ğŸ“Š ä¸²è¡Œæ‰§è¡Œ:     {serial_time:.2f}s (åŸºå‡†)")
        logger.info(f"ğŸ“Š æ ‡å‡†å¹¶å‘:     {concurrent_time:.2f}s (æå‡ {concurrent_speedup:.2f}x)")
        logger.info(f"ğŸ“Š ä¼˜åŒ–å¹¶è¡Œ:     {parallel_time:.2f}s (æå‡ {parallel_speedup:.2f}x)")
        logger.info(f"ğŸ‰ å¹¶è¡Œ vs å¹¶å‘: å¿« {parallel_vs_concurrent:.2f}x ({(parallel_vs_concurrent-1)*100:.1f}% æ›´å¿«)")
        
        # éªŒè¯ç»“æœä¸€è‡´æ€§
        logger.info("\nğŸ” ç»“æœéªŒè¯:")
        success_count = sum(1 for r in parallel_results if r and not r.startswith("Error:"))
        logger.info(f"âœ… æˆåŠŸå¤„ç†: {success_count}/{len(test_prompts)} ä¸ªè¯·æ±‚")
        
        # æ˜¾ç¤ºéƒ¨åˆ†ç»“æœ
        logger.info("\nğŸ“ éƒ¨åˆ†ç»“æœå±•ç¤º:")
        for i, (prompt, result) in enumerate(zip(test_prompts[:3], parallel_results[:3])):
            logger.info(f"   Q{i+1}: {prompt[:30]}...")
            if result and not result.startswith("Error:"):
                logger.info(f"   A{i+1}: {result[:60]}...")
            else:
                logger.info(f"   A{i+1}: [å¤„ç†å¤±è´¥]")
        
        return {
            'serial_time': serial_time,
            'concurrent_time': concurrent_time,
            'parallel_time': parallel_time,
            'parallel_speedup': parallel_speedup,
            'success_rate': success_count / len(test_prompts)
        }
        
    except Exception as e:
        logger.error(f"âŒ æ¼”ç¤ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

def demo_real_world_scenario():
    """æ¼”ç¤ºçœŸå®ä¸–ç•Œåœºæ™¯ï¼šæ‰¹é‡æ–‡æ¡£å¤„ç†"""
    logger.info("\nğŸŒ çœŸå®åœºæ™¯æ¼”ç¤ºï¼šæ‰¹é‡æ–‡æ¡£æ‘˜è¦ç”Ÿæˆ")
    logger.info("="*50)
    
    # æ¨¡æ‹Ÿæ–‡æ¡£å†…å®¹
    documents = [
        "äººå·¥æ™ºèƒ½æŠ€æœ¯åœ¨è¿‡å»åå¹´ä¸­å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œç‰¹åˆ«æ˜¯åœ¨æ·±åº¦å­¦ä¹ ã€è‡ªç„¶è¯­è¨€å¤„ç†å’Œè®¡ç®—æœºè§†è§‰é¢†åŸŸã€‚è¿™äº›æŠ€æœ¯çš„å‘å±•ä¸ä»…æ¨åŠ¨äº†ç§‘æŠ€è¡Œä¸šçš„åˆ›æ–°ï¼Œä¹Ÿåœ¨åŒ»ç–—ã€é‡‘èã€æ•™è‚²ç­‰å¤šä¸ªé¢†åŸŸäº§ç”Ÿäº†æ·±è¿œå½±å“ã€‚",
        "äº‘è®¡ç®—ä½œä¸ºç°ä»£ä¿¡æ¯æŠ€æœ¯çš„é‡è¦ç»„æˆéƒ¨åˆ†ï¼Œä¸ºä¼ä¸šæä¾›äº†çµæ´»ã€å¯æ‰©å±•çš„è®¡ç®—èµ„æºã€‚é€šè¿‡äº‘æœåŠ¡ï¼Œä¼ä¸šå¯ä»¥é™ä½ITæˆæœ¬ï¼Œæé«˜è¿è¥æ•ˆç‡ï¼Œå¹¶å¿«é€Ÿå“åº”å¸‚åœºå˜åŒ–ã€‚ä¸»è¦çš„äº‘æœåŠ¡æ¨¡å¼åŒ…æ‹¬IaaSã€PaaSå’ŒSaaSã€‚",
        "åŒºå—é“¾æŠ€æœ¯ä»¥å…¶å»ä¸­å¿ƒåŒ–ã€ä¸å¯ç¯¡æ”¹çš„ç‰¹æ€§ï¼Œåœ¨æ•°å­—è´§å¸ã€ä¾›åº”é“¾ç®¡ç†ã€æ•°å­—èº«ä»½éªŒè¯ç­‰é¢†åŸŸå±•ç°å‡ºå·¨å¤§æ½œåŠ›ã€‚è¿™é¡¹æŠ€æœ¯æœ‰æœ›é‡å¡‘ä¼ ç»Ÿçš„å•†ä¸šæ¨¡å¼å’Œä¿¡ä»»æœºåˆ¶ã€‚",
        "æœºå™¨å­¦ä¹ ç®—æ³•èƒ½å¤Ÿä»å¤§é‡æ•°æ®ä¸­è‡ªåŠ¨å‘ç°æ¨¡å¼å’Œè§„å¾‹ï¼Œä¸ºå†³ç­–æä¾›æ”¯æŒã€‚ç›‘ç£å­¦ä¹ ã€æ— ç›‘ç£å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ æ˜¯ä¸‰ç§ä¸»è¦çš„æœºå™¨å­¦ä¹ èŒƒå¼ï¼Œå„è‡ªé€‚ç”¨äºä¸åŒç±»å‹çš„é—®é¢˜ã€‚",
        "ç‰©è”ç½‘æŠ€æœ¯å°†ç‰©ç†ä¸–ç•Œä¸æ•°å­—ä¸–ç•Œè¿æ¥èµ·æ¥ï¼Œé€šè¿‡ä¼ æ„Ÿå™¨ã€ç½‘ç»œå’Œæ•°æ®åˆ†æï¼Œå®ç°æ™ºèƒ½åŒ–çš„ç›‘æ§å’Œæ§åˆ¶ã€‚è¿™é¡¹æŠ€æœ¯åœ¨æ™ºæ…§åŸå¸‚ã€å·¥ä¸š4.0å’Œæ™ºèƒ½å®¶å±…ç­‰é¢†åŸŸæœ‰ç€å¹¿æ³›åº”ç”¨ã€‚",
        "é‡å­è®¡ç®—åˆ©ç”¨é‡å­åŠ›å­¦åŸç†è¿›è¡Œä¿¡æ¯å¤„ç†ï¼Œåœ¨æŸäº›ç‰¹å®šé—®é¢˜ä¸Šå…·æœ‰æŒ‡æ•°çº§çš„è®¡ç®—ä¼˜åŠ¿ã€‚è™½ç„¶ç›®å‰ä»å¤„äºå‘å±•é˜¶æ®µï¼Œä½†é‡å­è®¡ç®—æœ‰æœ›åœ¨å¯†ç å­¦ã€ä¼˜åŒ–é—®é¢˜å’Œç§‘å­¦æ¨¡æ‹Ÿç­‰é¢†åŸŸå¸¦æ¥é©å‘½æ€§çªç ´ã€‚"
    ]
    
    # ç”Ÿæˆæ‘˜è¦æç¤º
    summary_prompts = [
        f"è¯·ä¸ºä»¥ä¸‹æ–‡æ¡£ç”Ÿæˆä¸€ä¸ªç®€æ´çš„æ‘˜è¦ï¼ˆä¸è¶…è¿‡50å­—ï¼‰ï¼š\n\n{doc}"
        for doc in documents
    ]
    
    try:
        client = OptimizedMultiModelClient()
        
        logger.info(f"ğŸ“„ å¾…å¤„ç†æ–‡æ¡£: {len(documents)} ä¸ª")
        logger.info(f"ğŸ–¥ï¸ å¯ç”¨å®ä¾‹: {len(client.model_instances)} ä¸ª")
        
        # å¹¶è¡Œç”Ÿæˆæ‘˜è¦
        logger.info("\nğŸš€ å¼€å§‹å¹¶è¡Œç”Ÿæˆæ‘˜è¦...")
        start_time = time.time()
        summaries = client.generate_parallel(summary_prompts, max_tokens=60)
        processing_time = time.time() - start_time
        
        logger.info(f"âœ… å¤„ç†å®Œæˆï¼Œè€—æ—¶: {processing_time:.2f}s")
        logger.info(f"âš¡ å¹³å‡æ¯ä¸ªæ–‡æ¡£: {processing_time/len(documents):.2f}s")
        
        # æ˜¾ç¤ºç»“æœ
        logger.info("\nğŸ“‹ æ–‡æ¡£æ‘˜è¦ç»“æœ:")
        logger.info("-" * 60)
        
        for i, (doc, summary) in enumerate(zip(documents, summaries), 1):
            logger.info(f"\nğŸ“„ æ–‡æ¡£ {i}:")
            logger.info(f"   åŸæ–‡: {doc[:80]}...")
            if summary and not summary.startswith("Error:"):
                logger.info(f"   æ‘˜è¦: {summary.strip()}")
            else:
                logger.info(f"   æ‘˜è¦: [ç”Ÿæˆå¤±è´¥]")
        
        # ç»Ÿè®¡ä¿¡æ¯
        success_count = sum(1 for s in summaries if s and not s.startswith("Error:"))
        logger.info(f"\nğŸ“Š å¤„ç†ç»Ÿè®¡:")
        logger.info(f"   æˆåŠŸç‡: {success_count}/{len(documents)} ({success_count/len(documents)*100:.1f}%)")
        logger.info(f"   æ€»è€—æ—¶: {processing_time:.2f}s")
        logger.info(f"   ååé‡: {len(documents)/processing_time:.1f} æ–‡æ¡£/ç§’")
        
        return {
            'documents_processed': len(documents),
            'processing_time': processing_time,
            'success_rate': success_count / len(documents),
            'throughput': len(documents) / processing_time
        }
        
    except Exception as e:
        logger.error(f"âŒ çœŸå®åœºæ™¯æ¼”ç¤ºå¤±è´¥: {e}")
        return None

def demo_scalability_test():
    """æ¼”ç¤ºå¯æ‰©å±•æ€§æµ‹è¯•ï¼šä¸åŒè´Ÿè½½ä¸‹çš„æ€§èƒ½"""
    logger.info("\nğŸ“ˆ å¯æ‰©å±•æ€§æµ‹è¯•ï¼šä¸åŒè´Ÿè½½ä¸‹çš„æ€§èƒ½è¡¨ç°")
    logger.info("="*50)
    
    try:
        client = OptimizedMultiModelClient()
        
        # æµ‹è¯•ä¸åŒçš„è´Ÿè½½å¤§å°
        load_sizes = [2, 4, 6, 8, 10]
        base_prompt = "è¯·ç®€å•è§£é‡Šä»¥ä¸‹æ¦‚å¿µï¼š"
        concepts = ["äººå·¥æ™ºèƒ½", "æœºå™¨å­¦ä¹ ", "æ·±åº¦å­¦ä¹ ", "ç¥ç»ç½‘ç»œ", "è‡ªç„¶è¯­è¨€å¤„ç†", 
                   "è®¡ç®—æœºè§†è§‰", "å¼ºåŒ–å­¦ä¹ ", "æ•°æ®æŒ–æ˜", "å¤§æ•°æ®", "äº‘è®¡ç®—"]
        
        results = []
        
        for load_size in load_sizes:
            logger.info(f"\nğŸ§ª æµ‹è¯•è´Ÿè½½: {load_size} ä¸ªè¯·æ±‚")
            
            # å‡†å¤‡æµ‹è¯•æç¤º
            test_prompts = [f"{base_prompt}{concepts[i % len(concepts)]}" 
                          for i in range(load_size)]
            
            # æ‰§è¡Œæµ‹è¯•
            start_time = time.time()
            responses = client.generate_parallel(test_prompts, max_tokens=40)
            execution_time = time.time() - start_time
            
            # ç»Ÿè®¡ç»“æœ
            success_count = sum(1 for r in responses if r and not r.startswith("Error:"))
            throughput = load_size / execution_time
            
            result = {
                'load_size': load_size,
                'execution_time': execution_time,
                'success_count': success_count,
                'success_rate': success_count / load_size,
                'throughput': throughput
            }
            results.append(result)
            
            logger.info(f"   â±ï¸ æ‰§è¡Œæ—¶é—´: {execution_time:.2f}s")
            logger.info(f"   âœ… æˆåŠŸç‡: {success_count}/{load_size} ({result['success_rate']*100:.1f}%)")
            logger.info(f"   ğŸš€ ååé‡: {throughput:.1f} è¯·æ±‚/ç§’")
        
        # åˆ†æå¯æ‰©å±•æ€§
        logger.info("\nğŸ“Š å¯æ‰©å±•æ€§åˆ†æ:")
        logger.info("-" * 40)
        
        for result in results:
            efficiency = result['throughput'] / results[0]['throughput'] if results[0]['throughput'] > 0 else 1.0
            logger.info(f"è´Ÿè½½ {result['load_size']:2d}: {result['execution_time']:5.2f}s, "
                       f"{result['throughput']:5.1f} req/s, æ•ˆç‡ {efficiency:.2f}x")
        
        return results
        
    except Exception as e:
        logger.error(f"âŒ å¯æ‰©å±•æ€§æµ‹è¯•å¤±è´¥: {e}")
        return None

def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    logger.info("ğŸ¬ å¤šæ¨¡å‹å¹¶è¡Œæ‰§è¡Œå®Œæ•´æ¼”ç¤º")
    logger.info("="*80)
    
    # æ¼”ç¤º1: æ€§èƒ½å¯¹æ¯”
    perf_results = demo_performance_comparison()
    
    # æ¼”ç¤º2: çœŸå®åœºæ™¯
    real_world_results = demo_real_world_scenario()
    
    # æ¼”ç¤º3: å¯æ‰©å±•æ€§æµ‹è¯•
    scalability_results = demo_scalability_test()
    
    # æ€»ç»“
    logger.info("\nğŸ‰ æ¼”ç¤ºæ€»ç»“")
    logger.info("="*40)
    
    if perf_results:
        logger.info(f"âœ… æ€§èƒ½æå‡: {perf_results['parallel_speedup']:.2f}x")
        logger.info(f"âœ… æˆåŠŸç‡: {perf_results['success_rate']*100:.1f}%")
    
    if real_world_results:
        logger.info(f"âœ… æ–‡æ¡£å¤„ç†ååé‡: {real_world_results['throughput']:.1f} æ–‡æ¡£/ç§’")
    
    if scalability_results:
        max_throughput = max(r['throughput'] for r in scalability_results)
        logger.info(f"âœ… æœ€å¤§ååé‡: {max_throughput:.1f} è¯·æ±‚/ç§’")
    
    logger.info("\nğŸš€ å¤šæ¨¡å‹å¹¶è¡Œç³»ç»Ÿå·²å‡†å¤‡å°±ç»ªï¼Œå¯ä»¥æ˜¾è‘—æé«˜å¤„ç†æ•ˆç‡ï¼")

if __name__ == "__main__":
    main()