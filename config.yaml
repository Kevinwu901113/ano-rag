# ANO-RAG 系统统一配置文件
# 本配置文件包含了向量检索增强生成系统的所有核心参数

# 系统基础配置
system:
  project_name: "ano-rag"  # 项目名称，用于标识和日志记录
  # seed: 42                 # 随机种子，确保实验结果可复现
  device: "cuda"            # 计算设备：cpu/cuda，影响模型推理速度

# 文档处理配置
document:
  chunk_size: 256          # 文档分块大小（字符数），影响检索粒度
  overlap: 32              # 分块间重叠字符数，保证语义连续性

# 嵌入模型配置
embedding:
  model_name: "BAAI/bge-m3"  # 嵌入模型名称，支持中英文多语言
  batch_size: 64             # 批处理大小，影响嵌入生成速度
  max_length: 512            # 最大token长度，超出部分会被截断
  normalize: true            # 是否对向量进行归一化，提高相似度计算准确性

# 原子笔记字段归一化与词表
note_keys:
  rel_lexicon:
    performed_by: ["performed by", "the performer is", "由", "演奏"]
    spouse_of: ["spouse", "partner", "married to", "配偶", "伴侣"]
    born_in: ["born in", "出生于", "出生在"]
    released_in: ["released in", "发行于", "发行在"]
    member_of: ["member of", "成员", "属于"]
  type_hints:
    album: ["(album)"]
    song: ["(song)"]
    film: ["(film)"]
    person: ["(person)", "先生", "女士", "Dr."]
  normalize:
    strip_quotes: true
    collapse_space: true
    lower: false

# 原子笔记图构建权重
graph:
  edge:
    key_match_weight: 1.5
    type_compat_weight: 1.0
    same_paragraph_bonus: 0.3

# Beam Search 多跳检索参数
multi_hop:
  max_hops: 4
  beam_size: 8
  branch_factor: 6

# 关系链答案选择器
answer_selector:
  enabled: true
  anchor_top_k: 5
  use_candidate_pool: true
  apply_before_llm: true

# 向量存储配置
vector_store:
  top_k: 20                 # 检索候选数量，影响召回率和计算开销
  similarity_threshold: 0.15 # 相似度阈值，低阈值提高召回率但可能引入噪声
  batch_size: 64            # 向量检索批处理大小
  dimension: 1024           # 向量维度，需与嵌入模型匹配
  index_type: "IVFFlat"     # FAISS索引类型，影响检索速度和精度
  nlist: 20                 # IVF索引聚类数量，避免训练数据不足警告
  similarity_metric: "cosine" # 相似度计算方法：cosine/euclidean/dot_product

# 检索策略配置
retrieval:
  bm25_topk_hop1: 40         # 原来若 <=15，建议拉高
  embed_topk_hop1: 30
  bm25_topk_hop2: 12
  embed_topk_hop2: 8
  query_rewrites_hop1: 2     # 针对桥接实体，生成 2 个改写
  title_dedup: true          # 同一 title 仅留 1 段
  entity_norm_dedup: true
  candidate_pool: 80        # 全局候选池大小，影响最终检索质量
  min_per_subq: 1          # 每个子问题最小召回数量，硬约束
  
  # JSON解析重试配置
  json_parsing:
    max_retries: 3           # 最大重试次数，增加重试次数可减少空答案
    enable_smart_fallback: true  # 启用智能回退逻辑，避免返回空答案
    fallback_message: "Unable to extract a meaningful answer from the provided context"  # 自定义回退消息
  # 性能控制配置
  performance:
    max_fallback_per_step: 8      # 每个回补步骤的最大候选数量
    max_graph_expansion: 15        # 图扩展的最大候选数量
    max_entity_lookup: 12          # 实体查找的最大实体数量
    fallback_timeout_ms: 1000     # 回补检索超时时间（毫秒）
    max_total_fallback: 10        # 总回补候选数量上限
  # 图感知两阶段rerank配置
  use_graph_rerank: true    # 是否启用图感知两阶段rerank
  seeds_semantic: 50        # 语义检索种子节点数量
  seeds_bm25: 30           # BM25检索种子节点数量
  subgraph_radius: 2       # 子图截取半径
  edge_thresh: 0.35        # 边权阈值过滤
  k_paths: 20              # 生成路径数量上限
  pick_paths: 4            # 选择路径数量
  overlap_thresh: 0.5      # 路径重叠阈值
  token_budget: 1800       # token预算
  alpha: 0.5               # 终点相似度权重
  beta: 0.3                # 路径平均权重
  gamma: 0.2               # 上下文覆盖权重
  rho: 0.25                # 上下文覆盖上限
  lambda_len: 0.05         # 路径长度惩罚系数
  query_mode: auto         # 查询模式：precise/explanatory/auto
  
  # 扩展配置
  expansion:
    max_neighbors_hop1: 3      # K-hop 扩展扇出
    max_neighbors_hop2: 2
    degree_cap: 50             # 图上高频节点的邻居上限（防止百科类节点爆炸）
  
  # 重排配置
  rerank:
    cross_encoder: "bge-reranker-large"  # 或 monoT5 / E5-reranker
    final_topk: 15
    margin_threshold: 0.15     # 低于阈值的直接裁掉
    diversity_by_title: true
    
    # ListT5重排序配置
    use_listt5: true           # 是否启用ListT5重排序
    listt5_model: "castorini/doc2query-t5-large-list"  # ListT5模型名称
    listt5_input_topk: 50      # 进入ListT5的候选数量
    keep_after_listt5: 25      # ListT5重排后保留的候选数量
    max_seq_len: 2048          # ListT5最大序列长度
    batch_size: 4              # ListT5批处理大小
  
  # 上下文配置
  context:
    max_tokens: 1800           # 控制"准而不泛滥"，避免把无关段落一并带入
    per_title_max: 1
    per_entity_sentences: 2    # 从命中的段落摘 2 句"证据句"
    evidence_first: true       # 证据句放在每段开头
  
  # 桥接感知配置
  bridge_aware:
    hop2_query: "{bridge_entity} {question_subgoal}"  # 二跳检索必须包含一跳的桥实体
    require_bridge_hit: true   # hop2 候选中至少要有若干桥实体命中
  hybrid:                   # 混合检索配置
    enabled: true           # 是否启用混合检索（向量+BM25+图谱）
    fusion_method: "linear"  # 融合方法：linear线性加权|rrf倒数排名融合|weighted_sum加权求和
    weights:                # 各检索方法权重配置
      dense: 1.0            # 密集向量检索权重
      bm25: 0.5             # BM25关键词检索权重
      graph: 0.35            # 知识图谱检索权重
    # 二跳候选安全网配置
    second_hop_safety:
      keep_top_m: 5         # 二跳候选Top-M无条件保活数量
      lower_threshold: 0.10 # 二跳候选放宽阈值（低于此分数的会被过滤）
    # 多跳检索配置
    multi_hop:
      max_hops: 4                # 允许的最大跳数（3/4）
      beam_width: 8              # 每跳实体/候选保留的宽度（控制爆炸）
      per_hop_keep_top_m: 5      # 每跳候选 Top-M 保活（安全网）
      focused_weight_by_hop:     # 关系聚焦相似度在不同跳的权重（随跳数衰减）
        1: 0.30
        2: 0.25
        3: 0.20
        4: 0.15
      hop_decay: 0.85            # 跳数惩罚（final_score *= hop_decay^(hop_no-1)）
      lower_threshold: 0.10      # 多跳候选放宽阈值（尾部过滤）
    answer_bias:
      who_person_boost: 1.10     # 人物类问题答案增强

# 混合搜索配置
hybrid_search:
  prf_bridge:
    enabled: true
    first_hop_topk: 2       # 统计桥接实体的来源数
    prf_topk: 20            # 二次小检索条数
  fusion:
    dense_weight: 1.0
    bm25_weight: 0.6
    focused_weight_hop2: 0.30   # 二跳聚焦相似度权重（不是谓词，只是聚焦查询）
    rrf_lambda: 0.2
  features:
    cov_weight: 0.10        # 实体覆盖率
    cons_weight: 0.05       # 路径一致性
    hop_decay: 0.85
  cluster_suppression:
    enabled: true
    cos_threshold: 0.90
    keep_per_cluster: 2
  safety:
    per_hop_keep_top_m: 6
    lower_threshold: 0.10
    keep_one_per_doc: true

  # 重排权重配置
  rerank:
    entity_overlap_weight: 0.4     # 实体重叠打分权重
    path_consistency_weight: 0.3   # 链路一致性打分权重
    semantic_weight: 0.35           # 语义相似度权重
    soft_penalty_no_entity: 0.7    # 无实体命中时的软惩罚系数
    rrf_k: 60               # RRF融合参数，仅在fusion_method为rrf时使用

# 校准配置
calibration:
  path: "calibration.json"    # 校准文件路径
  listt5_weight: 0.35         # ListT5与现有融合器的融合权重
  listt5_temperature: 1.0     # ListT5温度缩放参数
  bm25:                     # BM25检索参数
    k1: 1.2                 # 词频饱和参数，控制词频对得分的影响
    b: 0.75                 # 文档长度归一化参数
    text_field: "title_raw_span" # BM25检索的文本字段
  graph:                    # 图谱检索配置
    enabled: true           # 是否启用知识图谱检索
    k_hop: 4                # 图谱遍历跳数，影响关联实体发现范围
    expand_top_m: 50        # 图谱扩展的top-m候选数量
    expand_k: 1             # 图扩展时的一跳扩展限制
    db_path: "data/graph.db"  # 图数据库路径
    max_depth: 2            # 图遍历最大深度
    min_score: 0.3          # 最小相关性分数阈值
    max_nodes: 50           # 单次查询最大节点数
  multi_hop:                # 多跳检索配置
    enabled: true           # 是否启用多跳检索（false时使用混合图检索策略）
    # 图检索策略配置
    strategy: "hybrid"       # 图检索策略：entity_extraction|top_k_seed|hybrid
    top_k_seed:             # Top-K种子节点策略配置
      enabled: false       # 是否启用Top-K种子节点策略
      seed_count: 5         # 作为种子节点的Top-K数量
      fallback_to_entity: true  # 当Top-K结果不足时是否回退到实体提取策略
    entity_extraction:      # 实体提取策略配置（传统方式）
      enabled: true         # 是否启用实体提取策略
      max_entities: 10      # 最大提取实体数量
    hybrid_mode:            # 混合策略配置
      primary_strategy: "entity_extraction"  # 主策略：entity_extraction|top_k_seed
      fallback_strategy: "top_k_seed"       # 备用策略
      switch_threshold: 3   # 主策略结果不足时的切换阈值

# 路径感知检索配置
path_aware:
  enabled: true            # 是否启用路径感知检索，提高多跳推理能力
  min_path_score: 0.05       # 最小路径得分阈值

# 结果分发器配置
dispatcher:
  final_semantic_count: 7   # 最终语义检索结果数量（减少）
  final_graph_count: 30      # 最终图谱检索结果数量（增加）
  bridge_policy: "boost"  # 桥接策略：none无|keepalive保活|boost增强
  bridge_boost_epsilon: 0.03  # 桥接增强的epsilon参数
  debug_log: true           # 是否输出调试日志

# 调度器配置
scheduler:
  coverage_guard: true      # 是否启用覆盖守卫，确保每个子问题至少有一条证据

# 大语言模型配置
llm:
  provider: "hybrid_llm"      # LLM提供商：lmstudio/openai/ollama/hybrid_llm等
  model: "openai/gpt-oss-20b"   # 模型名称，需与provider匹配
  temperature: 0.1          # 生成温度，控制输出随机性（0-1）
  max_output_tokens: 8192    # 最大输出token数量
  
  # 混合LLM配置（当provider为hybrid_llm时生效）
  hybrid_llm:
    mode: "task_division"    # 混合模式：task_division任务划分|competitive竞争模式
    
    # 轻量级任务配置（使用Ollama）
    light_tasks:
      model: "qwen2.5:latest" # 轻量级任务模型
      base_url: "http://localhost:11434"  # Ollama服务地址
      timeout: 30             # 请求超时时间（秒）
      max_async: 16            # 最大异步请求数
      # max_tokens: 1024        # 最大输出token数
      num_ctx: 32768           # 上下文窗口大小
      temperature: 0.1        # 生成温度
    
    # 重量级任务配置（使用LM Studio）
    heavy_tasks:
      provider: "lmstudio"    # 重量级任务提供商
      model: "openai/gpt-oss-20b"  # 重量级任务模型
      base_url: "http://localhost:1234/v1"  # LM Studio服务地址
      instances: 1            # LM Studio实例数量
      timeout: 60             # 请求超时时间（秒）

# 检索护栏配置
guardrail:
  enabled: false             # 是否启用检索护栏，防止低质量结果
  min_results: 1            # 最少检索结果数量
  min_score: 0.0            # 最低检索得分阈值
  timeout_seconds: 30       # 检索超时时间（秒）

# 新增功能配置开关
feature_switches:
  # 稳定note_id生成功能
  stable_note_id:
    enabled: true           # 是否启用基于源文档信息的稳定note_id生成
    use_content_hash: true  # 是否使用内容哈希作为备选方案
    fallback_to_index: true # 无其他信息时是否回退到索引方式

# 原子笔记生成并行处理配置
atomic_note_generation:
  # 并行处理策略
  parallel_enabled: true        # 是否启用并行处理
  parallel_strategy: "task_division"  # 并行策略：task_division任务分配|competitive竞争模式|quality_selection质量选择
  
  # 任务分配配置（task_division策略）
  task_division:
    enabled: true               # 是否启用任务分配策略
    allocation_method: "batch_split"  # 分配方法：round_robin轮询|batch_split批次分割
    enable_fallback: true       # 是否启用失败回退机制
    fallback_timeout: 60        # 回退超时时间（秒）- 增加到60秒以避免超时错误
    
  # Ollama配置（用于原子笔记生成）
  ollama:
    model: "qwen2.5:latest"     # Ollama模型名称
    base_url: "http://localhost:11434"  # Ollama服务地址
    timeout: 30                 # 请求超时时间（秒）
    max_async: 16               # 最大异步请求数
    temperature: 0.1            # 生成温度
    
  # LM Studio配置（用于原子笔记生成）
  lmstudio:
    model: "qwen2.5-7b-instruct"     # LM Studio模型名称
    base_url: "http://localhost:1234/v1"  # LM Studio服务地址
    timeout: 60                 # 请求超时时间（秒）
    temperature: 0.1            # 生成温度
    
  # 性能监控配置
  monitoring:
    enabled: true               # 是否启用性能监控
    log_stats: true             # 是否记录统计信息
    export_metrics: false       # 是否导出性能指标

# 原子笔记生成优化配置
notes_llm:
  max_note_chars: 200
  # 流式处理早停机制配置
  stream_early_stop: true      # 启用流式处理早停机制
  sentinel_char: "~"           # 哨兵字符，表示0条笔记，首字符为此字符时立即停止
  enable_fast_path: true       # 启用快速路径优化
  retry_once_on_parse_error: true  # 解析错误时重试一次
  shorten_on_retry_chars: 1000 # 重试时缩短chunk长度
  min_chars: 20                # 笔记最小字符数
  max_chars: 400               # 笔记最大字符数
  min_salience: 0.3            # 最小显著性阈值
  max_notes_per_chunk: 12      # 每个chunk最大笔记数
  enable_rule_fallback: true   # 启用规则回退机制
  entities_fallback:
    enabled: true
    min_len: 2
    types: ["PERSON", "ORG", "GPE", "WORK_OF_ART", "EVENT"]
  limit:
    strategy: bucketed
    bucket:
      by: paragraph_idx
      quota_per_bucket: 1
  # LLM调用参数优化
  llm_params:
    temperature: 0             # 生成温度设为0，确保确定性输出
    top_p: 0                   # top_p设为0，进一步确保确定性
    max_tokens: 128            # 限制输出长度，提高响应速度
    stop: ["\n\n", "~"]        # 停止标记，遇到双换行或哨兵字符时停止

notes_prompt:
  element_conservation: true        # 启用显式要素守恒提示（主体/时间/地点等不可拆散）
  enumeration_split: true           # 对枚举项重复主体拆分完整句
  enforce_entity_slot: true         # 强制提醒实体字段补全
  preserve_relationships: true      # 保留人物关系信息

note_completeness:
  require_sentence_terminal: true
  allowed_sentence_terminals: ["。", ".", "!", "?"]

  # 长度下限（避免标题/短片段）
  min_word_count_en: 4
  min_char_count_zh: 8

  # 句子必须包含谓词（英文/中文动词线索）
  verb_patterns_en:
    - "\\b(is|are|was|were|has|have|had|includes?|included|include|acquired|founded|located|born|won|announced|reported|published|proposed|launched)\\b"
  verb_patterns_zh:
    - "(是|为|位于|属于|出生|成立|获得|提出|报道|宣布|包含|推出|发布)"

  # 禁止以从属/介词等开头（英文/中文）
  bad_starts_en:
    - "^(because|due to|such as|including|with|without|after|before)\\b"
  bad_starts_zh:
    - "^(因为|由于|其中|包括|以及)"

  # entities 字段要求
  require_entities: false

quality_filter:
  require_entities: true
  min_chars: 20

note_recovery:
  enable: true
  jaccard_threshold: 0.6
  merge_threshold: 0.35
  max_merge_tokens: 30
  max_new_notes: 3

evaluation:
  coverage_thresholds:
    warning: 0.7
    critical: 0.5
  coverage_report_path: "debug/coverage_report.json"
  coverage:
    threshold: 0.6
    critical_threshold: 0.5
    min_sentence_tokens: 6
    report_path: "debug/coverage_report.json"
    missing_sentences_path: "debug/missing_sentences.jsonl"

# 增强关系提取配置
enhanced_relation_extraction:
  use_llm_extraction: true     # 是否启用LLM增强的语义关系提取
  use_fast_model: true          # 是否使用快速模型
  enable_topic_groups: true     # 是否启用主题组关系提取
  enable_reasoning_paths: false  # 是否启用推理路径关系提取
  
  # 轻量级关系类型功能
  lightweight_relations:
    enabled: true           # 是否启用轻量级商业关系识别
    relation_types:         # 支持的关系类型配置
      succession: true      # 继任关系
      acquisition: true     # 收购关系
      ownership: true       # 归属关系
      subsidiary: true      # 子公司关系
      partnership: true     # 合作关系
      merger: true          # 合并关系
    keyword_matching: true  # 是否启用关键词匹配
    pattern_matching: true  # 是否启用模式匹配
  
  # 一致性检查功能
  consistency_check:
    enabled: true           # 是否启用数据写入前的一致性检查
    strict_mode: false      # 严格模式：发现严重错误时停止处理
    check_note_id: true     # 检查note_id一致性
    check_entity_alignment: true  # 检查实体对齐
    check_relation_chains: true   # 检查关系链完整性
    check_source_binding: true    # 检查源文档绑定稳定性
    check_graph_structure: true   # 检查图结构完整性
    entity_alignment_threshold: 0.8  # 实体对齐警告阈值（80%实体缺失才警告）
    export_report: true     # 是否导出检查报告
    report_format: "json"   # 报告格式：json/yaml/txt
